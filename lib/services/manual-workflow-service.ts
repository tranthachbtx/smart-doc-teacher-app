
import { ProcessingModule } from "@/lib/store/use-app-store";
import { SmartPromptData } from "./smart-prompt-service";
import { LessonPlanAnalyzer } from "./lesson-plan-analyzer";
import { ProfessionalContentProcessor } from "./professional-content-processor";
import { LegacyResilienceAdapter } from "./legacy-resilience-adapter";

export interface PromptContext {
    topic: string;
    grade: string;
    fileSummary: string;
    optimizedFileSummary?: string;
    previousContext?: string;
    smartData?: SmartPromptData;
}

export const ManualWorkflowService = {
    /**
     * Ph√¢n t√≠ch c·∫•u tr√∫c b√†i h·ªçc t·ª´ n·ªôi dung vƒÉn b·∫£n.
     */
    analyzeStructure(text: string, duration: string): ProcessingModule[] {
        const analyzed = LessonPlanAnalyzer.analyze(text);

        // N·∫øu c√≥ c√°c ho·∫°t ƒë·ªông ƒë∆∞·ª£c tr√≠ch xu·∫•t, ta c√≥ th·ªÉ t·∫°o c√°c module t∆∞∆°ng ·ª©ng
        // Tuy nhi√™n, ƒë·ªÉ linh ho·∫°t theo chu·∫©n 5512 (4 b∆∞·ªõc), ta v·∫´n gi·ªØ 4 module ch√≠nh,
        // nh∆∞ng c√≥ th·ªÉ b·ªï sung th√¥ng tin t·ª´ file v√†o ti√™u ƒë·ªÅ ho·∫∑c n·ªôi dung.

        const modules: ProcessingModule[] = [
            { id: "mod_khoi_dong", title: "Ho·∫°t ƒë·ªông 1: Kh·ªüi ƒë·ªông (M·ªü ƒë·∫ßu)", type: "khoi_dong", prompt: "", content: "", isCompleted: false },
            { id: "mod_kham_pha", title: "Ho·∫°t ƒë·ªông 2: H√¨nh th√†nh ki·∫øn th·ª©c m·ªõi (Kh√°m ph√°)", type: "kham_pha", prompt: "", content: "", isCompleted: false },
            { id: "mod_luyen_tap", title: "Ho·∫°t ƒë·ªông 3: Luy·ªán t·∫≠p", type: "luyen_tap", prompt: "", content: "", isCompleted: false },
            { id: "mod_van_dung", title: "Ho·∫°t ƒë·ªông 4: V·∫≠n d·ª•ng", type: "van_dung", prompt: "", content: "", isCompleted: false }
        ];
        return modules;
    },

    /**
     * Helper to validate and clean file summary
     */
    validateAndCleanFileSummary(fileSummary: string): string {
        if (!fileSummary || fileSummary.trim().length === 0 || fileSummary === "N·ªôi dung s√°ch gi√°o khoa...") {
            return "Kh√¥ng c√≥ n·ªôi dung g·ªëc ƒë∆∞·ª£c cung c·∫•p. H√£y d·ª±a v√†o ki·∫øn th·ª©c chuy√™n m√¥n v√† ch·ªß ƒë·ªÅ ƒë·ªÉ thi·∫øt k·∫ø ho·∫°t ƒë·ªông.";
        }
        return fileSummary;
    },

    /**
     * T·∫°o Prompt "x·ªãn" cho t·ª´ng module ƒë·ªÉ user copy sang Gemini Pro Web/ChatGPT
     */
    async generatePromptForModule(module: ProcessingModule, context: PromptContext): Promise<string> {
        // High-Precision Logic: Use pre-optimized content if available, otherwise process the raw summary
        let optimizedContent = "";

        if (context.optimizedFileSummary) {
            optimizedContent = context.optimizedFileSummary;
        } else {
            const baseContent = ManualWorkflowService.validateAndCleanFileSummary(context.fileSummary);
            const processedContent = ProfessionalContentProcessor.extractActivityContent(baseContent);
            optimizedContent = ProfessionalContentProcessor.optimizeForActivity(module.type, processedContent);
        }

        const contextInjection = context.previousContext
            ? `\n[CONTEXT_UPDATE]: Ho·∫°t ƒë·ªông tr∆∞·ªõc ƒë√≥ ƒë√£ ho√†n th√†nh. H√£y ti·∫øp n·ªëi m·∫°ch b√†i h·ªçc n√†y ƒë·ªÉ t·∫°o s·ª± logic.\nB·ªëi c·∫£nh c≈©: ${context.previousContext}\n`
            : "";

        let smartDataSection = "";
        if (context.smartData) {
            const sd = context.smartData;
            // ... (Smart Data Filtering Logic remains same)

            // SMART FILTERING ENGINE: S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c g√°n nh√£n cho t·ª´ng ho·∫°t ƒë·ªông
            const mission = sd.coreMissions[module.type === 'khoi_dong' ? 'khoiDong' :
                module.type === 'kham_pha' ? 'khamPha' :
                    module.type === 'luyen_tap' ? 'luyenTap' : 'vanDung'];

            const specificAdvice = `
## üõ°Ô∏è EXCLUSIVE DIRECTIVE (QUAN TR·ªåNG):
- CH·ªà t·∫≠p trung v√†o giai ƒëo·∫°n: ${module.title.toUpperCase()}.
- TUY·ªÜT ƒê·ªêI kh√¥ng l·∫∑p l·∫°i n·ªôi dung ƒë√£ thu·ªôc v·ªÅ c√°c giai ƒëo·∫°n kh√°c.
- D·ª∞A TR√äN NGHI·ªÜM V·ª§ C·ªêT L√ïI SAU:
${mission}
`;

            smartDataSection = `
## üí° CH·ªà D·∫™N TH√îNG MINH T·ª™ DATABASE (C·ª• th·ªÉ cho ho·∫°t ƒë·ªông n√†y):
${specificAdvice}
----------------------------------
`;
        }

        // Prepare Semantic Context (Step 2 Implementation)
        const semanticContext = context.optimizedFileSummary && typeof context.optimizedFileSummary === 'object'
            ? {
                instructions: (context.optimizedFileSummary as any).semanticTags?.instructions,
                tasks: (context.optimizedFileSummary as any).semanticTags?.studentTasks,
                knowledge: (context.optimizedFileSummary as any).semanticTags?.knowledgeCores
            }
            : null;

        // Use ProfessionalContentProcessor for optimized prompt generation
        return (await ProfessionalContentProcessor.generateOptimizedPrompt(
            module.type,
            typeof optimizedContent === 'string' ? optimizedContent : JSON.stringify(optimizedContent),
            context.smartData,
            null,
            true, // skipNeural: TRUE for manual prompt generation
            semanticContext
        )) + contextInjection + smartDataSection;
    },

    /**
     * Generate optimized prompt using ProfessionalContentProcessor
     */
    async generateOptimizedPromptForModule(module: ProcessingModule, context: PromptContext): Promise<string> {
        // Process content with ProfessionalContentProcessor
        const processedContent = ProfessionalContentProcessor.extractActivityContent(context.fileSummary);
        const optimizedContent = ProfessionalContentProcessor.optimizeForActivity(module.type, processedContent);

        // Generate optimized prompt (Now Async)
        return await ProfessionalContentProcessor.generateOptimizedPrompt(
            module.type,
            optimizedContent,
            context.smartData,
            context.previousContext ? { summary: context.previousContext } : null,
            true // skipNeural: TRUE
        );
    },

    /**
     * RESTORED ARCHITECTURE 18.0 ROBUST MODE
     * Uses multi-step reasoning to generate high-quality initial draft.
     */
    async generateRobustModules(text: string, context: PromptContext): Promise<ProcessingModule[]> {
        const adapter = LegacyResilienceAdapter.getInstance();
        const result = await adapter.processDocumentRobustly(
            text,
            context.smartData!,
            context.topic,
            context.grade
        );
        return result.modules;
    }
};
