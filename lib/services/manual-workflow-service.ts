
import { ProcessingModule } from "@/lib/store/use-app-store";
import { SmartPromptData } from "./smart-prompt-service";
import { ProfessionalContentProcessor } from "./professional-content-processor";

export interface PromptContext {
    topic: string;
    grade: string;
    fileSummary: string;
    optimizedFileSummary?: string;
    previousContext?: string;
    smartData?: SmartPromptData;
}

export const ManualWorkflowService = {
    /**
     * Ph√¢n t√≠ch c·∫•u tr√∫c b√†i h·ªçc t·ª´ n·ªôi dung vƒÉn b·∫£n.
     */
    analyzeStructure(text: string, duration: string): ProcessingModule[] {
        // V7: Comprehensive structure for manual workflow (MoET 5512)
        const modules: ProcessingModule[] = [
            { id: "mod_setup", title: "B∆∞·ªõc 1: M·ª•c ti√™u & Thi·∫øt b·ªã (Ph·∫ßn I, II, III)", type: "setup", prompt: "", content: "", isCompleted: false },
            { id: "mod_shdc", title: "B∆∞·ªõc 2: Sinh ho·∫°t D∆∞·ªõi c·ªù", type: "shdc", prompt: "", content: "", isCompleted: false },
            { id: "mod_khoi_dong", title: "B∆∞·ªõc 3: Ho·∫°t ƒë·ªông 1 - Kh·ªüi ƒë·ªông", type: "khoi_dong", prompt: "", content: "", isCompleted: false },
            { id: "mod_kham_pha", title: "B∆∞·ªõc 4: Ho·∫°t ƒë·ªông 2 - Kh√°m ph√°", type: "kham_pha", prompt: "", content: "", isCompleted: false },
            { id: "mod_luyen_tap", title: "B∆∞·ªõc 5: Ho·∫°t ƒë·ªông 3 - Luy·ªán t·∫≠p", type: "luyen_tap", prompt: "", content: "", isCompleted: false },
            { id: "mod_van_dung", title: "B∆∞·ªõc 6: Ho·∫°t ƒë·ªông 4 - V·∫≠n d·ª•ng", type: "van_dung", prompt: "", content: "", isCompleted: false },
            { id: "mod_shl", title: "B∆∞·ªõc 7: Sinh ho·∫°t L·ªõp", type: "shl", prompt: "", content: "", isCompleted: false },
            { id: "mod_appendix", title: "B∆∞·ªõc 8: Ph·ª• l·ª•c & D·∫∑n d√≤ (Ph·∫ßn V, VI)", type: "appendix", prompt: "", content: "", isCompleted: false }
        ];
        return modules;
    },

    /**
     * Helper to validate and clean file summary
     */
    validateAndCleanFileSummary(fileSummary: string): string {
        if (!fileSummary || fileSummary.trim().length === 0 || fileSummary === "N·ªôi dung s√°ch gi√°o khoa...") {
            return "Kh√¥ng c√≥ n·ªôi dung g·ªëc ƒë∆∞·ª£c cung c·∫•p. H√£y d·ª±a v√†o ki·∫øn th·ª©c chuy√™n m√¥n v√† ch·ªß ƒë·ªÅ ƒë·ªÉ thi·∫øt k·∫ø ho·∫°t ƒë·ªông.";
        }
        return fileSummary;
    },

    /**
     * T·∫°o Prompt "x·ªãn" cho t·ª´ng module ƒë·ªÉ user copy sang Gemini Pro Web/ChatGPT
     */
    async generatePromptForModule(module: ProcessingModule, context: PromptContext): Promise<string> {
        // High-Precision Logic: Use pre-optimized content if available, otherwise process the raw summary
        let optimizedContent = "";

        if (context.optimizedFileSummary) {
            optimizedContent = context.optimizedFileSummary;
        } else {
            const baseContent = ManualWorkflowService.validateAndCleanFileSummary(context.fileSummary);
            const processedContent = ProfessionalContentProcessor.extractActivityContent(baseContent);
            optimizedContent = ProfessionalContentProcessor.optimizeForActivity(module.type, processedContent);
        }

        const contextInjection = context.previousContext
            ? `\n[CONTEXT_UPDATE]: Ho·∫°t ƒë·ªông tr∆∞·ªõc ƒë√≥ ƒë√£ ho√†n th√†nh. H√£y ti·∫øp n·ªëi m·∫°ch b√†i h·ªçc n√†y ƒë·ªÉ t·∫°o s·ª± logic.\nB·ªëi c·∫£nh c≈©: ${context.previousContext}\n`
            : "";

        let smartDataSection = "";
        if (context.smartData) {
            const sd = context.smartData;

            // SMART FILTERING ENGINE: S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c g√°n nh√£n cho t·ª´ng ho·∫°t ƒë·ªông
            let mission = "";
            switch (module.type) {
                case 'khoi_dong': mission = sd.coreMissions.khoiDong; break;
                case 'kham_pha': mission = sd.coreMissions.khamPha; break;
                case 'luyen_tap': mission = sd.coreMissions.luyenTap; break;
                case 'van_dung': mission = sd.coreMissions.vanDung; break;
                default: mission = "Nhi·ªám v·ª• chung t·ª´ chuy√™n gia.";
            }

            const specificAdvice = `
## üõ°Ô∏è EXCLUSIVE DIRECTIVE (QUAN TR·ªåNG):
- CH·ªà t·∫≠p trung v√†o giai ƒëo·∫°n: ${module.title.toUpperCase()}.
- TUY·ªÜT ƒê·ªêI kh√¥ng l·∫∑p l·∫°i n·ªôi dung ƒë√£ thu·ªôc v·ªÅ c√°c giai ƒëo·∫°n kh√°c.
- D·ª∞A TR√äN NGHI·ªÜM V·ª§ C·ªêT L√ïI SAU:
${mission}
`;

            smartDataSection = `
## üí° CH·ªà D·∫™N TH√îNG MINH T·ª™ DATABASE (C·ª• th·ªÉ cho ho·∫°t ƒë·ªông n√†y):
${specificAdvice}
----------------------------------
`;
        }

        // Prepare Semantic Context (Step 2 Implementation)
        const semanticContext = context.optimizedFileSummary && typeof context.optimizedFileSummary === 'object'
            ? {
                instructions: (context.optimizedFileSummary as any).semanticTags?.instructions,
                tasks: (context.optimizedFileSummary as any).semanticTags?.studentTasks,
                knowledge: (context.optimizedFileSummary as any).semanticTags?.knowledgeCores,
                products: (context.optimizedFileSummary as any).semanticTags?.products,
                assessment: (context.optimizedFileSummary as any).semanticTags?.assessment
            }
            : null;

        // Use ProfessionalContentProcessor for optimized prompt generation
        const prompt = await ProfessionalContentProcessor.generateOptimizedPrompt(
            module.type,
            typeof optimizedContent === 'string' ? optimizedContent : JSON.stringify(optimizedContent),
            context.smartData,
            null,
            true, // skipNeural: TRUE for manual prompt generation
            semanticContext
        );

        return prompt + contextInjection + smartDataSection;
    },

    /**
     * Generate optimized prompt using ProfessionalContentProcessor
     */
    async generateOptimizedPromptForModule(module: ProcessingModule, context: PromptContext): Promise<string> {
        // Process content with ProfessionalContentProcessor
        const processedContent = ProfessionalContentProcessor.extractActivityContent(context.fileSummary);
        const optimizedContent = ProfessionalContentProcessor.optimizeForActivity(module.type, processedContent);

        // Generate optimized prompt (Now Async)
        return await ProfessionalContentProcessor.generateOptimizedPrompt(
            module.type,
            optimizedContent,
            context.smartData,
            context.previousContext ? { summary: context.previousContext } : null,
            true // skipNeural: TRUE
        );
    },

    /**
     * V7 Note: Robust generation is now handled directly by PedagogicalOrchestrator
     * in the automatic workflow. Manual workflow uses generatePromptForModule.
     */
};
